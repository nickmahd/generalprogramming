{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"target\",\"id\",\"date\",\"flag\",\"user\",\"text\"]\n",
    "data = pd.read_csv(\"https://www.kaggle.com/kazanova/sentiment140/data\", names=columns, index_col=False)\n",
    "# Download the dataset linked here ^ and\n",
    "\n",
    "data.drop([\"flag\",\"date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete = re.compile(\"[.;:!\\'?,\\\"()\\[\\]*%$&^{}\\\\<>+=\\-_]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"].replace(delete, \"\", regex=True)\n",
    "data[\"text\"] = data[\"text\"].map(lambda x: \"\".join([\"\" if \"@\" in l else l+\" \" for l in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test  = data.iloc[0::2].reset_index(drop=True)\n",
    "df_train = data.iloc[1::2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = list(df_train[\"text\"])\n",
    "tests = list(df_test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(tweets)\n",
    "X = vectorizer.transform(tweets)\n",
    "X_test = vectorizer.transform(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=list(df_train[\"target\"])\n",
    "target_test=list(df_test[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01: 0.78603625\n",
      "C=0.05: 0.79417\n",
      "C=0.25: 0.79679625\n",
      "C=0.5: 0.7964025\n",
      "C=1: 0.79519375\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X, target)\n",
    "    print (\"C=%s: %s\" % (c, accuracy_score(target_test, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.79679625\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.25)\n",
    "model.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('worries', 2.195456811966638)\n",
      "('smiling', 2.0360304485790928)\n",
      "('pleasure', 1.9308718835996483)\n",
      "('congratulations', 1.8983993713855165)\n",
      "('welcome', 1.8640109852922537)\n",
      "('sad', -3.0353807287748684)\n",
      "('rip', -2.611159114085779)\n",
      "('sadly', -2.5755503992475752)\n",
      "('disappointing', -2.533280269023295)\n",
      "('fathers', -2.5214688997324273)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {word: coef for word, coef in zip(vectorizer.get_feature_names(), model.coef_[0])}\n",
    "\n",
    "for best_positive in sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "\n",
    "for best_negative in sorted(feature_to_coef.items(), key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.78603625\n"
     ]
    }
   ],
   "source": [
    "model2 = LogisticRegression(C=0.01)\n",
    "model2.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target_test, model2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('thanks', 1.4589126544621156)\n",
      "('welcome', 1.3926073711360265)\n",
      "('thank', 1.2536384530280948)\n",
      "('excited', 1.1545051093182543)\n",
      "('glad', 1.1453016719181912)\n",
      "('sad', -2.5664253227601814)\n",
      "('miss', -2.072448674501172)\n",
      "('sucks', -1.8509703880678698)\n",
      "('poor', -1.81921839810167)\n",
      "('missing', -1.7559944884977308)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {word: coef for word, coef in zip(vectorizer.get_feature_names(), model2.coef_[0])}\n",
    "\n",
    "for best_positive in sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "\n",
    "for best_negative in sorted(feature_to_coef.items(), key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.76096375\n"
     ]
    }
   ],
   "source": [
    "model2 = LogisticRegression(C=0.001)\n",
    "model2.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" % accuracy_score(target_test, model2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('thanks', 1.1210364239110544)\n",
      "('happy', 0.7739457733382591)\n",
      "('thank', 0.7390255941767985)\n",
      "('great', 0.7082352886986772)\n",
      "('love', 0.6929043812828807)\n",
      "('sad', -1.5149240090928795)\n",
      "('miss', -1.40320095914648)\n",
      "('sorry', -0.991527692992244)\n",
      "('hate', -0.9518025883213777)\n",
      "('wish', -0.94933310020284)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {word: coef for word, coef in zip(vectorizer.get_feature_names(), model2.coef_[0])}\n",
    "\n",
    "for best_positive in sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "\n",
    "for best_negative in sorted(feature_to_coef.items(), key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is actually pretty interesting\n",
    "\n",
    "It turns out, as the regularization and accuracy increase, the words become more and more \"overfit\", in that they make less sense. E.g., \"fathers\" probably doesn't belong in the negative sentiment words list.\n",
    "\n",
    "One possible explanation is that accuracy is a bad measure for this, and that it would be better to use another measure to figure out which regularization coefficient to use. Also, working with other hyperparameters might have helped the model be more accurate. I wrote this all at 11 pm though, so I'm probably going to try that stuff out some other time when I'm not trying to get sleep :/\n",
    "\n",
    "In conclusion I should probably get some more knowlege about logistic regression\n",
    "\n",
    "Borrowed the top/bottom words calculator and some other bits+pieces from https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
